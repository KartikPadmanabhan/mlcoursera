sum(d1[]=='Mon')
sub<-function(d){format(d,"%a%y")}
d1<-sapply(sampleTimes,sub)
View(d1)
sum(d1[]=='Mon12')
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv","t1.csv",method="curl")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv","t2.csv",method="curl")
t1<-read.csv('t1.csv')
View(t1)
t1<-read.csv('t1.csv',skip=4,colnames<-c("CTRY","RNK"))
t1<-read.csv('t1.csv',skip=4,colnames<-c("CTRY","RNK"),header=FALSE)
t1<-read.csv('t1.csv',skip=4,colnames<-c("CTRY","RNK"),header=FALSE,sep=",")
View(t1)
t1<-read.table('t1.csv',skip=4,colnames<-c("CTRY","RNK"),header=FALSE,sep=",")
download.file("https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv","t1.csv",method="curl")
t1<-read.csv('t1.csv',skip=4)
View(t1)
colnames(t1)
t1<-read.csv('t1.csv')
View(t1)
tmp<-read.csv('t1.csv')
View(tmp)
t1<-read.csv('t1.csv',skip=4)
View(t1)
t2<-read.csv('t2.csv')
View(t2)
?merge
mergeData<-merge(t1,t2,by.x="X",by.y="CountryCode")
View(mergeData)
sub<-function(d){grepl("[^[Ff]iscal year end: [Jj]une]",d)}
d1<-sapply(mergeData$Special.Notes,sub)
d1
sum(d1[]==TRUE)
sub<-function(d){grepl("[^Fiscal year end: June]",d)}
d1<-sapply(mergeData$Special.Notes,sub)
sum(d1[]==TRUE)
d1
str<-"Fiscal year end: June 30; reporting period for national accounts data: FY."
sub(str)
str<-"Fiscal year end: june 30; reporting period for national accounts data: FY."
sub(str)
str<-"Fiscal year ; reporting period for national accounts data: FY."
sub(str)
sub<-function(d){grepl("[^Fiscal year end]",d)}
str<-"Fiscal year ; reporting period for national accounts data: FY."
sub(str)
sub<-function(d){grepl("[^Fiscal year end\:]",d)}
sub<-function(d){grepl("[^Fiscal year end]",d)}
str<-"Fiscal year ; reporting period for national accounts data: FY."
sub(str)
str<-"Fiscal year reporting period for national accounts data: FY."
sub(str)
sub<-function(d){grepl("^[Fiscal year end]",d)}
sub(str)
str<-"Fiscal year reporting period for national accounts data: FY."
sub(str)
sub<-function(d){grep("^[Fiscal year end]",d)}
sub(str)
str
sub<-function(d){grep("^Fiscal year end",d)}
sub(str)
sub<-function(d){grepl("^Fiscal year end",d)}
sub(str)
str<-"Fiscal year end: June reporting period for national accounts data: FY."
sub(str)
sub<-function(d){grepl("^Fiscal year end:",d)}
sub(str)
sub<-function(d){grepl("^Fiscal year end: June",d)}
sub(str)
s
str
sub<-function(d){grepl("^Fiscal year end: June",d)}
d1<-sapply(mergeData$Special.Notes,sub)
sum(d1)
str(airquality)
class(airquality$Month)
?pden
?pbeta
install.library("nutshell")
library(nutshell)
download.file(fileURL,destfile="dataset.zip",method="curl")
x <- 1:4
p <- x/sum(x)
temp <- rbind(x, p)
rownames(temp) <- c("X", "Prob")
temp
1*0.1
(1*0.1)
(1*0.1) + (2*.2) + (3*0.3) + (4*0.4)
library(datasets)
data(airquality)
library(datasets)
data(airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
install.library('ggplot')
install.library('ggplot2')
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
library(ggplot2)
library(ggplot)
library(ggplot2)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
library(ggplot)
install.packages(''ggplot2)
install.packages(''ggplot2'')
install.packages('ggplot2')
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
install.packages(qplot)
install.packages(ggplot2)
install.packages('ggplot2')
library(ggplot2)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
airquality = transform(airquality, Month = factor(Month))
q
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
apropos("^panel")
a<-c(140,138,150,148,135)
b<-c(132,135,151,146,130)
t.test(a,b,paired=TRUE)
?pt
ppois(9,17.87,lower.tail=TRUE)
power.t.test(power=.9, delta=.1, sd=.04, type="one.sample", alt="one.sided")$n
power.t.test(power=.9, delta=.01, sd=.04, type="one.sample", alt="one.sided")$n
power.t.test(n=100, delta=.01, sd=.04, type="one.sample", alt="one.sided")$n
power.t.test(n=100, delta=.01, sd=.04, type="one.sample", alt="one.sided")
power.t.test(n=100, delta=.01, sd=.04, type="one.sample", alt="one.sided")
power.t.test(power=.9, delta=.01, sd=.04, type="one.sample", alt="one.sided")
2*pnorm(-abs(0.047150271983819437))
2*pnorm(-abs(0.0136111111111111))
ppois(10,17.87,lower.tail=FALSE)
ppois(10,17.87,lower.tail=TRUE)
2*pnorm(-abs(1.96))
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
x'
''
x2
x^2
library(mlbench)
data(BostonHousing)
library(manipulate)
install.packages('manipulate')
install.package('manipulate')
install.packages('manipulate')
install.package('manipulate')
install.packages('manipulate')
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
install.packages('manipulate')
library(manipulate)
hist(galton$child,col="blue",breaks=100)
hist(x)
?rep
?Cor
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
fit=x~y
fit
fit=lm(x~y)
fit
fit=lm(y~x)
fit
date(mtcats)
date(mtcars)
mtcars
lm(mtcars$mpg~mtcars$wt)
lm(mtcars$wt~mtcars$mpg)
x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
std(x)
stdev(x)
mean(x)
?stf
?std
sd(x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
X.1 <- c(x.1,-sum(x.1))
Y.1 <- c(y.1,-sum(y.1))
y <- rnorm(20, mean=0)
y
x <- rnorm(20, mean=0)
x
lm(y~x)
lm(y~x)
x <- rnorm(20, mean=0)
y <- rnorm(20, mean=0)
lm(y~x)
mean(y)
mean(x)
a<-(-2,-3,0,2,3)
a<-c(-2,-3,0,2,3)
y<-c(-4,-6,0,6,4)
mean(a)
mean(y)
lm(y~a)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
lm(x~x)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
lm(x~y)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
lm(y~x)
lm(x~y)
lm(y~x-1)
lm(formula = y ~ x - 1)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
set.seed(125)
summary(segmentationOriginal)
str(segmentationOriginal)
s<-sample(dim(fg1)[1],119)
s<-sample(dim(segmentationOriginal)[1],119)
test<-segmentationOriginal[s,]
train<-segmentationOriginal[-s,]
summary(test)
summary(train)
library(rpart)
p1<-rpart(Class~.,data=train)
plot(p1)
test(p1)
text(p1)
text(p1)
p1<-rpart(Class~.,data=train)
plot(p1)
text(p1)
printcp(p1)
plotcp(fit)
summary(fit)
summary(p1)
View(segmentationOriginal)
dim(segmentationOriginal)[2]
dim(segmentationOriginal)[1]
dim(segmentationOriginal)[3]
?sample
library(rpart)
s<-subset(segmentationOriginal,Case)
test<-subset(segmentationOriginal,Case='Test')
test
summary(test)
View(test)
test<-subset(segmentationOriginal,Case=='Test')
View(test)
train<-subset(segmentationOriginal,Case=='Train')
p1<-rpart(Class~.,data=train)
plot(p1)
text(p1)
p1
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages(pgmm)
install.packages('pgmm')
library(pgmm)
data(olive)
olive = olive[,-1]
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages('pgmm')
install.packages("pgmm_1.0.tar.gz", repos=NULL, type="source")
getwd()
install.packages("pgmm_1.0.tar.gz", repos=NULL, type="source")
install.packages("pgmm_1.0.tar.gz", repos=NULL, type="source")
load(url("https://dl.dropboxusercontent.com/u/47814734/olive.rda"))
head(olive)
load(url("http://dl.dropboxusercontent.com/u/47814734/olive.rda"))
head(olive)
olive = olive[,-1]
olive
summary(olive)
str(olive)
newdata = as.data.frame(t(colMeans(olive)))
newdata
test=newdata
test
train=olive
olive
summary(olive)
summary(train)
summary(test)
summary(test)
library(ipred)
install.packages('ipred')
library(ipred)
p2<-bagging(Area~.,data=train,coob=T)
p2
p1<-rpart(Area~., data=train)
p1
plot(p1)
text(p1)
View(test)
View(test)
View(olive)
library(ElemStatLearn)
install.packages('ElemStatLearn')
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
summary(trainSA)
set.seed(13234)
View(testSA)
p<- glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, family=binomial)
p
summary(p)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
prediction <- predict(p, newdata = testSA)
prediction
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(testSA,prediction)
set.seed(13234)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
p<- glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, family=binomial)
prediction <- predict(p, newdata = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA,prediction)
missClass(testSA$chd,prediction)
missClass(trainSA$chd,prediction)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
p<- glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, family=binomial)
set.seed(13234)
p<- glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data=trainSA, family=binomial)
prediction <- predict(p, newdata = testSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA$chd,prediction)
missClass(trainSA$chd,prediction)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
library(randomForest)
install.packages('randomForest')
library(randomForest)
View(vowel.test)
p3<-randomForest(y~.,data=vowel.train,importance=T)
p3
plot(p3)
arplot(p3$importance[,7])
barplot(p3$importance[,7])
p3$importance
barplot(p3$importance[,1])
data(mtcars)
summary(mtcars)
class(mtcars$cyl)
fit=lm(mpg~factor(cyl)+wt)
fit=lm(mtcars$mpg~factor(mtcars$cyl)+mtcars$wt)
summary(fit)
abline(fit)
factor(mtcars$cyl)
fit=lm(mtcars$mpg~factor(mtcars$cyl))
summary(fit)
fit=lm(mtcars$mpg~factor(mtcars$cyl)+mtcars$wt)
summary(fit)
fit1=lm(mtcars$mpg~factor(mtcars$cyl))
fit2=lm(mtcars$mpg~factor(mtcars$cyl)+mtcars$wt)
fit3=lm(mtcars$mpg~factor(mtcars$cyl)+mtcars$wt+factor(mtcars$cyl)*mtcars$wt)
anova(fit1,fit2,fit3)
fit1 <- lm(mpg ~ factor(cyl) + wt , data=mtcars)
fit2 <- lm(mpg ~ factor(cyl) + wt + cyl*wt, data=mtcars)
anova(fit1, fit2)
fit2 <- lm(mpg ~ factor(cyl) + wt + factor(cyl)*wt, data=mtcars)
anova(fit1, fit2)
summart(fit1)
summary(fit1)
summary(fit2)
anova(fit1, fit2)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
summary(lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars))
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
x
y
plot(x,y,frame=FALSE,cex=2,pch=21,bg="lightblue",col="black")
abline(lm(y~x))
fit<-lm(y~x)
hatvalues(fit)
dfbetas(fit)
summary(lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars))
summary(lm(mpg ~ I(wt) + factor(cyl), data = mtcars))
library(MASS)
fit<-lm(mpg ~ ., data = mtcars)
step <- stepAIC(fit, direction="both")
step$anova
plot(lm)
library(leaps)
install.packages('leaps')
mtcars$am
mtcars$carb
mtcars
Figure 3: Dependence of transmission type on the weight variable
source('~/.active-rstudio-document')
install.packages('knitrBootstrap')
library(knitrBootstrap)
library(rmarkdown)
install.packages('rmarkdown')
render('mtcars.Rmd', 'knitrBootstrap::bootstrap_document')
?mtcars
summary(p3)
barplot(p3$importance[, 8], main = "Importance (Gini Index)")
summary(output)
data.frame(Truth = testing$classe, Tree = predict(p1, testing, type = "class"))
summary(testing)
testing <- read.csv("testing.csv", header = T, na.strings = c("NA", ""))
getwd()
setwd("/Users/uthrakartik/fitbit")
testing <- read.csv("testing.csv", header = T, na.strings = c("NA", ""))
p1
p2
p3
setwd("/Users/uthrakartik/fitbit")
output<-data.frame(Truth = testing$classe, Tree = predict(p1, testing, type = "class"), Bagging = predict(p2, testing), Forest = predict(p3, testing))
output<-data.frame(Truth = testing$classe, Tree = predict(p1, testing, type = "class"))
testing$classe
summary(testing)
View(testing)
View(training)
training <- read.csv("training.csv", header = T, na.strings = c("NA", ""))
# remove columns from training set that consist mostly of NAs and blanks
training  <- training[, colSums(!is.na(training)) == nrow(training)]
# also remove other columns that actually do not sensor measurements
training <- subset(training, select = -c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2,cvtd_timestamp, new_window, num_window))
View(training)
summary(training$classe)
summary(testing$classe)
set.seed(1)
library(caret)
inTrain <- createDataPartition(y = finaltraining$classe, p = 0.7, list = FALSE)
training <- finaltraining[inTrain, ]  #13737 obs.
validation <- finaltraining[-inTrain, ]  #5885 obs.
# read training dataset for pre-processing
finaltraining <- read.csv("training.csv", header = T, na.strings = c("NA", ""))
# read testing dataset for pre-processing
finaltesting <- read.csv("testing.csv", header = T, na.strings = c("NA", ""))
# remove columns from training set that consist mostly of NAs and blanks
finaltraining  <- training[, colSums(!is.na(training)) == nrow(training)]
# also remove other columns that actually do not sensor measurements
finaltraining <- subset(training, select = -c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2,cvtd_timestamp, new_window, num_window))
# read training dataset for pre-processing
finaltraining <- read.csv("training.csv", header = T, na.strings = c("NA", ""))
# read testing dataset for pre-processing
finaltesting <- read.csv("testing.csv", header = T, na.strings = c("NA", ""))
# remove columns from training set that consist mostly of NAs and blanks
finaltraining  <- finaltraining[, colSums(!is.na(finaltraining)) == nrow(finaltraining)]
# also remove other columns that actually do not sensor measurements
finaltraining <- subset(finaltraining, select = -c(X, user_name, raw_timestamp_part_1, raw_timestamp_part_2,cvtd_timestamp, new_window, num_window))
set.seed(1)
library(caret)
inTrain <- createDataPartition(y = finaltraining$classe, p = 0.7, list = FALSE)
training <- finaltraining[inTrain, ]  #13737 obs.
validation <- finaltraining[-inTrain, ]  #5885 obs.
summary(training)
str(training)
str(testing)
str(validation)
c(Tree = errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)$error  Bagging = errorest(classe ~ ., data = validation, model = p2)$error, Forest = errorest(classe ~ ., data = validation, model = p3)$error)
c(Tree = errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)$error , Bagging = errorest(classe ~ ., data = validation, model = p2)$error, Forest = errorest(classe ~ ., data = validation, model = p3)$error)
mypredict.rpart <- function(object, newdata) {
predict(object, newdata = newdata, type = "class")
}
c(Tree = errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)$error , Bagging = errorest(classe ~ ., data = validation, model = p2)$error, Forest = errorest(classe ~ ., data = validation, model = p3)$error)
install.library('ipred')
install.packages('ipred')
install.packages("ipred")
install.packages("ipred")
install.packages("ipred")
library(ipred)
mypredict.rpart <- function(object, newdata) {
predict(object, newdata = newdata, type = "class")
}
c(Tree = errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)$error , Bagging = errorest(classe ~ ., data = validation, model = p2)$error, Forest = errorest(classe ~ ., data = validation, model = p3)$error)
errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)$error
errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)
errorest(classe ~ ., data = validation, model = rpart, predict = mypredict.rpart)
errorest(classe ~ ., data = validation, model = rpart, predict = mypredict.rpart)
errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)
?errorest
errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)$error
errorest(classe ~ ., data = validation, model = rpart, predict = mypredict.rpart)
errorest(classe ~ ., data = validation, model = p1, predict = mypredict.rpart)
install.packages("ipred")
install.packages("ipred")
install.packages("ipred")
install.packages("ipred")
